{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30a2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a9bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract text from the websites\n",
    "def extract_website_text(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.text, \"html.parser\")\n",
    "#extracting the text and title\n",
    "    title=soup.title.text.strip()\n",
    "    website_text=\"\"\n",
    "    paragraphs=soup.find_all('p')\n",
    "    for paragraph in paragraphs:\n",
    "        website_text += paragraph.get_text()+ '\\n'\n",
    "    return title, website_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d53fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting the excel file into a dataframe and reading it\n",
    "input_file=r\"C:\\Users\\HP\\Documents\\BlackCoffer assignment\\input.xlsx\"\n",
    "df=pd.read_excel(input_file)\n",
    "df\n",
    "#creating an output file to save the extracted texts\n",
    "output_record=\"output_folder\"\n",
    "os.makedirs(output_record, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdbf382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Text extracted and saved for blackassign0001\n",
      "Website Text extracted and saved for blackassign0002\n",
      "Website Text extracted and saved for blackassign0003\n",
      "Website Text extracted and saved for blackassign0004\n",
      "Website Text extracted and saved for blackassign0005\n",
      "Website Text extracted and saved for blackassign0006\n",
      "Website Text extracted and saved for blackassign0007\n",
      "Website Text extracted and saved for blackassign0008\n",
      "Website Text extracted and saved for blackassign0009\n",
      "Website Text extracted and saved for blackassign0010\n",
      "Website Text extracted and saved for blackassign0011\n",
      "Website Text extracted and saved for blackassign0012\n",
      "Website Text extracted and saved for blackassign0013\n",
      "Website Text extracted and saved for blackassign0014\n",
      "Website Text extracted and saved for blackassign0015\n",
      "Website Text extracted and saved for blackassign0016\n",
      "Website Text extracted and saved for blackassign0017\n",
      "Website Text extracted and saved for blackassign0018\n",
      "Website Text extracted and saved for blackassign0019\n",
      "Website Text extracted and saved for blackassign0020\n",
      "Website Text extracted and saved for blackassign0021\n",
      "Website Text extracted and saved for blackassign0022\n",
      "Website Text extracted and saved for blackassign0023\n",
      "Website Text extracted and saved for blackassign0024\n",
      "Website Text extracted and saved for blackassign0025\n",
      "Website Text extracted and saved for blackassign0026\n",
      "Website Text extracted and saved for blackassign0027\n",
      "Website Text extracted and saved for blackassign0028\n",
      "Website Text extracted and saved for blackassign0029\n",
      "Website Text extracted and saved for blackassign0030\n",
      "Website Text extracted and saved for blackassign0031\n",
      "Website Text extracted and saved for blackassign0032\n",
      "Website Text extracted and saved for blackassign0033\n",
      "Website Text extracted and saved for blackassign0034\n",
      "Website Text extracted and saved for blackassign0035\n",
      "Website Text extracted and saved for blackassign0036\n",
      "Website Text extracted and saved for blackassign0037\n",
      "Website Text extracted and saved for blackassign0038\n",
      "Website Text extracted and saved for blackassign0039\n",
      "Website Text extracted and saved for blackassign0040\n",
      "Website Text extracted and saved for blackassign0041\n",
      "Website Text extracted and saved for blackassign0042\n",
      "Website Text extracted and saved for blackassign0043\n",
      "Website Text extracted and saved for blackassign0044\n",
      "Website Text extracted and saved for blackassign0045\n",
      "Website Text extracted and saved for blackassign0046\n",
      "Website Text extracted and saved for blackassign0047\n",
      "Website Text extracted and saved for blackassign0048\n",
      "Website Text extracted and saved for blackassign0049\n",
      "Website Text extracted and saved for blackassign0050\n",
      "Website Text extracted and saved for blackassign0051\n",
      "Website Text extracted and saved for blackassign0052\n",
      "Website Text extracted and saved for blackassign0053\n",
      "Website Text extracted and saved for blackassign0054\n",
      "Website Text extracted and saved for blackassign0055\n",
      "Website Text extracted and saved for blackassign0056\n",
      "Website Text extracted and saved for blackassign0057\n",
      "Website Text extracted and saved for blackassign0058\n",
      "Website Text extracted and saved for blackassign0059\n",
      "Website Text extracted and saved for blackassign0060\n",
      "Website Text extracted and saved for blackassign0061\n",
      "Website Text extracted and saved for blackassign0062\n",
      "Website Text extracted and saved for blackassign0063\n",
      "Website Text extracted and saved for blackassign0064\n",
      "Website Text extracted and saved for blackassign0065\n",
      "Website Text extracted and saved for blackassign0066\n",
      "Website Text extracted and saved for blackassign0067\n",
      "Website Text extracted and saved for blackassign0068\n",
      "Website Text extracted and saved for blackassign0069\n",
      "Website Text extracted and saved for blackassign0070\n",
      "Website Text extracted and saved for blackassign0071\n",
      "Website Text extracted and saved for blackassign0072\n",
      "Website Text extracted and saved for blackassign0073\n",
      "Website Text extracted and saved for blackassign0074\n",
      "Website Text extracted and saved for blackassign0075\n",
      "Website Text extracted and saved for blackassign0076\n",
      "Website Text extracted and saved for blackassign0077\n",
      "Website Text extracted and saved for blackassign0078\n",
      "Website Text extracted and saved for blackassign0079\n",
      "Website Text extracted and saved for blackassign0080\n",
      "Website Text extracted and saved for blackassign0081\n",
      "Website Text extracted and saved for blackassign0082\n",
      "Website Text extracted and saved for blackassign0083\n",
      "Website Text extracted and saved for blackassign0084\n",
      "Website Text extracted and saved for blackassign0085\n",
      "Website Text extracted and saved for blackassign0086\n",
      "Website Text extracted and saved for blackassign0087\n",
      "Website Text extracted and saved for blackassign0088\n",
      "Website Text extracted and saved for blackassign0089\n",
      "Website Text extracted and saved for blackassign0090\n",
      "Website Text extracted and saved for blackassign0091\n",
      "Website Text extracted and saved for blackassign0092\n",
      "Website Text extracted and saved for blackassign0093\n",
      "Website Text extracted and saved for blackassign0094\n",
      "Website Text extracted and saved for blackassign0095\n",
      "Website Text extracted and saved for blackassign0096\n",
      "Website Text extracted and saved for blackassign0097\n",
      "Website Text extracted and saved for blackassign0098\n",
      "Website Text extracted and saved for blackassign0099\n",
      "Website Text extracted and saved for blackassign0100\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "#for retreiving the text from each url of the df\n",
    "for index, row in df.iterrows():\n",
    "    url_id=row[\"URL_ID\"]\n",
    "    url=row[\"URL\"]\n",
    "    #Extracting the text and title\n",
    "    title, website_text = extract_website_text(url)\n",
    "    #Saving the text \n",
    "    output_file_path=os.path.join(output_record, f'{url_id}.txt')\n",
    "    with open(output_file_path, \"w\", encoding='utf-8') as output_file:\n",
    "        output_file.write(f'Title: {title}\\n\\n')\n",
    "        output_file.write(website_text)\n",
    "    print(f'Website Text extracted and saved for {url_id}')\n",
    "print(\"Text and Title Extraction is Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6c674",
   "metadata": {},
   "source": [
    "### Note:-\n",
    "     - I used requests and Beautifulsoup libraries to extract text from the given urls.\n",
    "     - I created a input file variable to store the path of the folder where the Excel file input was stored \n",
    "     - Then created a dataframe to read the input file.\n",
    "     - Created a output_folder using \"os' makedirs module to store the extracted texts\".\n",
    "     - Using for loop it iterates through each URL and extracts the title and text content.\n",
    "     - It saves the Extracted text to individual .txt file with its URL_ID as its file name.\n",
    " - How to Run:-\n",
    "    -  Place the script in the same folder as Input.xlsx.\n",
    "    - Run the objective-1(data extraction).py script in jupyter notebook or vs code.\n",
    "    - Install Pandas, Beautifulsoup, Requests and os."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
